{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e468e6",
   "metadata": {},
   "source": [
    "## Design your own trigger\n",
    "\n",
    "The trigger decides what type of physics we record forever. While ATLAS has a suite of inclusive triggers, for example a trigger for events containing at least one electron/positron above 24 GeV or at least one hadronic jet above 400 GeV, there is also room for more specialised triggers that looks for events that look like a specific Standard Model or hypothetical new process. \n",
    "Good specialiased triggers do two things:\n",
    "- They have a good signal-to-noise ratio.\n",
    "- They select events at a low/affordable rate.\n",
    "\n",
    "Today, we are interested in the following process, the production of a Higgs boson via Vector Boson Fusion (VBF), which then decays to invisible particles. Decays of Higgs to invisible is an interesting search at ATLAS for new physics.\n",
    "\n",
    "\n",
    "The current MET trigger selects events containing total missing transverse energy (MET) of at least 200 GeV. Can we use the event topology to design a new trigger that makes our event selection more rich with events containing VBF Higgs$\\rightarrow E_T^{miss}$?\n",
    "\n",
    "<img img align=\"center\" src=\"https://bpb-us-w2.wpmucdn.com/web.sas.upenn.edu/dist/2/672/files/2020/03/Higgs_invisible_vbf_fig_01a.png\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adcdee3",
   "metadata": {},
   "source": [
    "## Trigger limitations\n",
    "\n",
    "Our trigger will have to fit into the current ATLAS rate budget. We have room for an additional trigger with a rate of 5 Hz. The current 200 GeV single $E_T^{miss}$ trigger has a rate of 35 Hz and a significance ($S/\\sqrt{B}$) of 1.31 for the VBF $H\\rightarrow E_T^{miss}$ process for 300 inverse femtobarns of collected data. Can we improve that?\n",
    "\n",
    "| 200 GeV MET Trigger Rate | VBF H trigger Max Allowed Rate | Rel. Reduction |\n",
    "| --- | --- | --- |\n",
    "| 35 Hz | 5 Hz | 0.14\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2f389b",
   "metadata": {},
   "source": [
    "### How to design your trigger?\n",
    "\n",
    "The code below sets up some histograms that may hint at some event features that might show a marked difference between signal (VBF H$\\rightarrow E_T^{miss}$) and background (data). You can use these features to apply an event selection that will enhance the signal-to-background ratio.\n",
    "\n",
    "**Remember**: Additional selections means we can lower the high 200 GeV threshold on the total missing transverse energy!\n",
    "\n",
    "You should also have a look at the following paper section 4.2 to get inspiration for event selections:\n",
    "- [\"Search for invisible Higgs-boson decays in events with vector-boson fusion signatures using 139 fbâˆ’1 of proton-proton data recorded by the ATLAS experiment\"](https://arxiv.org/abs/2202.07953)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378d27c2",
   "metadata": {},
   "source": [
    "### The final goal?\n",
    "\n",
    "Design a trigger that is affordable and has a high significance! A significance of 3 is good, of 5 is very good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8ee1bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ROOT\n",
    "import math\n",
    "\n",
    "# -- set up of common variables ---\n",
    "\n",
    "tree_name = \"mini\" # event \"tree\" in which information of each event in the data set are defined:\n",
    "                   # event level information, particles and their properties\n",
    "\n",
    "GeV = 1e-3 # convert MeV to GeV \n",
    "fb = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fb843b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- list of histograms --- \n",
    "# NOTE: Not all histograms are filled in the analysis code. \n",
    "# They hint at what could be interesting to look at, though!\n",
    "\n",
    "bin_width = 5 # GeV\n",
    "h_pt_min = 0\n",
    "h_pt_max = 450\n",
    "pt_bins = int((h_pt_max-h_pt_min)/bin_width)\n",
    "\n",
    "def get_histograms():\n",
    "    # photon histograms\n",
    "    hist_list = {}\n",
    "    hist_list[\"met_et\"] = ROOT.TH1F(\"h_met_et\",\"met_et; met ET [GeV]; events\", pt_bins,h_pt_min,h_pt_max)\n",
    "\n",
    "    hist_list[\"jet_n\"] = ROOT.TH1F(\"h_jet_n\",\"jet multiplicity; jet multiplicity; events\", 10, 0, 10)\n",
    "    hist_list[\"jet0_pt\"]= ROOT.TH1F(\"h_jet0_pt\",\"leading jet pT; leading jet pT [GeV]; events\", pt_bins,h_pt_min,h_pt_max)\n",
    "    hist_list[\"jet1_pt\"] = ROOT.TH1F(\"h_jet1_pt\",\"subleading jet pT; subleading jet pT [GeV]; events\", pt_bins,h_pt_min,h_pt_max)\n",
    "    hist_list[\"jet0_eta\"] = ROOT.TH1F(\"h_jet0_eta\",\"leading jet eta; leading jet eta; events\",100,-5,5)\n",
    "    hist_list[\"jet1_eta\"] = ROOT.TH1F(\"h_jet1_eta\",\"subleading jet eta; subleading jet eta; events\",100,-5,5)\n",
    "    hist_list[\"jet_dphi\"] = ROOT.TH1F(\"h_jet_dphi\",\"DeltaPhi(jet0,jet1); DeltaPhi; events\", 80, -4, 4)\n",
    "    hist_list[\"jet_deta\"] = ROOT.TH1F(\"h_jet_deta\",\"DeltaEta(jet0,jet1); DeltaEta; events\", 80, 0, 8)\n",
    "    hist_list[\"dijet_m\"]= ROOT.TH1F(\"h_dijet_m\",\"dijet mass; dijet mass [GeV]; events\", pt_bins*2,h_pt_min,h_pt_max*2)\n",
    "\n",
    "    hist_list[\"cutflow\"] = ROOT.TH1F(\"cutflow\", \"cutflow;cut;count\", 10,0,10)\n",
    "    \n",
    "    for hname, hist in hist_list.items():\n",
    "        hist.SetDirectory(0)\n",
    "\n",
    "    \n",
    "    return hist_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d25d2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# --- Trigger Selection Code --- \n",
    "# ------------------------------\n",
    "# This is where we implement the event selection of the trigger based on objects and combined object systems.\n",
    "# Since ATLAS Open Data does not have our process of interest, we first convert the leptons to missing energy,\n",
    "# to simulate our process. Our main background is Z->nunu.\n",
    "\n",
    "def analyse_events(tree, hist_list, max_events = -1):\n",
    "    \n",
    "    for hname, hist in hist_list.items():\n",
    "        hist.Reset()\n",
    "        \n",
    "    passed_cnt = 0\n",
    "    evt_cnt = 0\n",
    "    \n",
    "    met_thresh = 200\n",
    "\n",
    "    for event in tree:\n",
    "        \n",
    "        if evt_cnt >= max_events: break\n",
    "        evt_cnt += 1\n",
    "        ## -- calculating total met - see comment at top of cell -- \n",
    "        met_x = 0\n",
    "        met_y = 0\n",
    "        for ii in range(event.lep_n):\n",
    "            met_x += event.lep_pt[ii]*math.cos(event.lep_phi[ii])\n",
    "            met_y += event.lep_pt[ii]*math.sin(event.lep_phi[ii])\n",
    "        met_x += event.met_et*math.cos(event.met_phi)\n",
    "        met_y += event.met_et*math.sin(event.met_phi)\n",
    "        met_et_GeV = math.sqrt(met_x*met_x + met_y*met_y) * GeV\n",
    "        # --- \n",
    "    \n",
    "        hist_list[\"cutflow\"].Fill(\"total\",1)\n",
    "        hist_list[\"met_et\"].Fill(met_et_GeV)\n",
    "\n",
    "        # our initial MET trigger - can we lower the threshold by using other selections in parallel?\n",
    "        if met_et_GeV < met_thresh: continue\n",
    "        hist_list[\"cutflow\"].Fill(f\"{met_thresh}GeVMET\",1)\n",
    "        \n",
    "        # reconstruct jets - could come in handy\n",
    "        hist_list[\"jet_n\"].Fill(event.jet_n) \n",
    "        \n",
    "        if event.jet_n >= 2:\n",
    "            jet0 = ROOT.TLorentzVector()\n",
    "            jet0.SetPtEtaPhiE(event.jet_pt[0], event.jet_eta[0], event.jet_phi[0], event.jet_E[0])\n",
    "            jet1 = ROOT.TLorentzVector()\n",
    "            jet1.SetPtEtaPhiE(event.jet_pt[1], event.jet_eta[1], event.jet_phi[1], event.jet_E[1])\n",
    "        \n",
    "            jet0_pt_GeV = jet0.Pt()*GeV\n",
    "            jet1_pt_GeV = jet1.Pt()*GeV\n",
    "            jet0_eta = jet0.Eta()\n",
    "            jet1_eta = jet1.Eta() \n",
    "            \n",
    "            hist_list[\"jet0_pt\"].Fill(jet0_pt_GeV)\n",
    "            hist_list[\"jet1_pt\"].Fill(jet1_pt_GeV)\n",
    "            hist_list[\"jet0_eta\"].Fill(jet0_eta)\n",
    "            hist_list[\"jet1_eta\"].Fill(jet1_eta)\n",
    "        \n",
    "            \n",
    "        # <FILL ME>\n",
    "        \n",
    "        passed_cnt += 1\n",
    "\n",
    "        \n",
    "    return passed_cnt\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f7254e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# --- RETRIEVE MC SIGNAL -------\n",
    "# ------------------------------\n",
    "### You should not have to change anything here.\n",
    "\n",
    "signal_hist_list = get_histograms()\n",
    "\n",
    "base_url = \"https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/MC\"\n",
    "input_name = \"mc_345323.VBFH125_WW2lep.2lep.root\"\n",
    "\n",
    "infile = ROOT.TFile.Open(f\"{base_url}/{input_name}\")\n",
    "signal_tree = infile.Get(\"mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5823840b-03a7-4385-a8f4-cf81f0837726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# --- ANALYSE MC SIGNAL --------\n",
    "# ------------------------------\n",
    "### You should not have to change anything here.\n",
    "\n",
    "total_evts = signal_tree.GetEntries()\n",
    "\n",
    "# Get signal cross-section\n",
    "signal_tree.GetEntry(0)\n",
    "xsection = signal_tree.XSection * fb\n",
    "print(\"Signal x-section = %.4f fb\"%(xsection))\n",
    "\n",
    "# Analyse signal events\n",
    "max_evts = total_evts # can reduce max_evts for fast histogram analysis but NOTE for final result revert this to total_evts!\n",
    "scale_factor = total_evts/max_evts\n",
    "print(\"Processing %i events...\"%(max_evts))        \n",
    "passed_signal_events = analyse_events(signal_tree, signal_hist_list,max_evts) * scale_factor\n",
    "\n",
    "print(\"passed signal events = %.2f\"%(passed_signal_events))\n",
    "\n",
    "# Signal events are corrected by the cross-section.\n",
    "signal = passed_signal_events * xsection\n",
    "print(\"x-section corrected signal = %.2f\"%(signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d7fb2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# --- RETRIEVE BACKGROUND DATA ------\n",
    "# -----------------------------------\n",
    "### You should not have to change anything here.\n",
    "\n",
    "bg_hist_list = get_histograms()\n",
    "\n",
    "base_url = \"https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/Data\"\n",
    "input_name = \"data_A.2lep.root\"\n",
    "\n",
    "infile = ROOT.TFile.Open(f\"{base_url}/{input_name}\")\n",
    "infile.GetListOfKeys().Print()\n",
    "bg_tree = infile.Get(\"mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a5ebd7-ec13-46a6-9a8b-8dbe1cb86956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# --- ANALYSE BACKGROUND DATA -------\n",
    "# -----------------------------------\n",
    "### You should not have to change anything here.\n",
    "\n",
    "total_evts = bg_tree.GetEntries()\n",
    "\n",
    "# Analyse background events\n",
    "max_evts = total_evts # can reduce max_evts for fast histogram analysis but NOTE for final result revert this to total_evts!\n",
    "print(\"Processing %i events...\"%(max_evts))\n",
    "scale_factor = total_evts/max_evts\n",
    "passed_bg_events = analyse_events(bg_tree, bg_hist_list, max_evts) * scale_factor\n",
    "print(\"passed background events = %i\"%(passed_bg_events))\n",
    "\n",
    "# Background events are scaled by a factor 18 here as we have only analysed 1/18 of the 10 ifb dataset.\n",
    "background = passed_bg_events * 18\n",
    "print(\"scaled background = %i\"%(background))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df46ca2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# -- Plotting Code ---\n",
    "# ---------------------\n",
    "# Here we have a look at the distributions. Which distributions look very different\n",
    "# for signal (red) and background (blue) events? Can we use those differences to enhance\n",
    "# the signal selection of our trigger?\n",
    "# (NOTE: Ignore errors about histogram normalisation. This will happen for histograms we have not filled.)\n",
    "\n",
    "\n",
    "canvas = ROOT.TCanvas(\"Canvas\", \"c\", 1200, 800)\n",
    "canvas.Divide(4,3,0.001,0.001) # -> (3,4): 3 plots per row, 4 rows\n",
    "\n",
    "cnv = 1\n",
    "for hname in signal_hist_list:\n",
    "    signal_hist = signal_hist_list[hname]\n",
    "    bg_hist = bg_hist_list[hname]\n",
    "    signal_hist.SetFillColorAlpha(ROOT.kRed, 0.5)\n",
    "    bg_hist.SetFillColorAlpha(ROOT.kBlue, 0.5)\n",
    "    canvas.cd(cnv)\n",
    "    if not \"cutflow\" in hname:\n",
    "        bg_hist.DrawNormalized(\"HIST\")\n",
    "        signal_hist.DrawNormalized(\"HISTSAME\")\n",
    "    canvas.Draw()\n",
    "    cnv+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d12dad2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "canvas2 = ROOT.TCanvas(\"Canvas2\", \"c2\", 800, 600)\n",
    "\n",
    "signal_hist_cp = signal_hist_list[\"cutflow\"].Clone(\"sg_cutflow_cp\")\n",
    "signal_hist_cp.Scale(1./signal_hist_cp.GetMaximum())\n",
    "signal_hist_cp.Draw(\"H\")\n",
    "bg_hist_cp = bg_hist_list[\"cutflow\"].Clone(\"bg_cutflow_cp\")\n",
    "bg_hist_cp.Scale(1./bg_hist_cp.GetMaximum())\n",
    "bg_hist_cp.Draw(\"HSAME\")\n",
    "#ROOT.gPad.SetLogy()\n",
    "canvas2.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffb2a78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# --- Final Results ----\n",
    "# ----------------------\n",
    "# Now we calculate the significance of our signal after selection and our trigger \"rate\"\n",
    "\n",
    "import math\n",
    "\n",
    "reduction = background/51336 # denominator: Number of events of 200 GeV MET trigger\n",
    "lumi_factor = 30. # 30 * 10 inverse fb = 300 ifb, the total amount expected for LHC Run 3\n",
    "\n",
    "print(\"Passed signal events = %i\"%signal)\n",
    "print(\"Passed bg events = %i\"%background)\n",
    "print(\"Significance = %.2f \"%(signal*lumi_factor/math.sqrt(background*lumi_factor)))\n",
    "print(\"Background rate relative to 200 GeV MET trigger = %.3f\"%reduction )\n",
    "if reduction > 0.14:\n",
    "    print(\" -- Sorry, we can't afford this trigger.\")\n",
    "else:\n",
    "    print(\" -- We can afford this trigger if it is worth the physics (good significance)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81430f3-74d8-4672-b31a-90a8d21a89ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
